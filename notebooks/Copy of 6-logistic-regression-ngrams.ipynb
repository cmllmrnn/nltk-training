{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of 6-logistic-regression-ngrams.ipynb","version":"0.3.2","provenance":[{"file_id":"1YllrWSzJy-tD92QEA1AvogGtIyEo1ZA5","timestamp":1534488169779},{"file_id":"1LZNF_ZRZiBVX8YhBw0TLfmv1-8aum7Jb","timestamp":1534481695905}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"aQLNbVJcQMiY","colab_type":"text"},"cell_type":"markdown","source":["Code for TensorBoard\n","==="]},{"metadata":{"id":"VkaMehYdIwIQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":234},"outputId":"39a69d40-90f7-4f27-cd73-1ee1f1d33213","executionInfo":{"status":"ok","timestamp":1534492172026,"user_tz":-480,"elapsed":6909,"user":{"displayName":"Camille Occeño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116044928297955637522"}}},"cell_type":"code","source":["!rm -rf logs/\n","!rm ngrok*\n","!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip ngrok-stable-linux-amd64.zip"],"execution_count":19,"outputs":[{"output_type":"stream","text":["--2018-08-17 07:49:29--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 52.1.117.85, 52.204.188.97, 52.20.145.121, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|52.1.117.85|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5363700 (5.1M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip’\n","\n","ngrok-stable-linux- 100%[===================>]   5.11M  22.6MB/s    in 0.2s    \n","\n","2018-08-17 07:49:30 (22.6 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"metadata":{"id":"47plbab5I2Jr","colab_type":"code","colab":{}},"cell_type":"code","source":["LOG_DIR = 'logs'\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zcq21uFLI9ju","colab_type":"code","colab":{}},"cell_type":"code","source":["get_ipython().system_raw('./ngrok http 6006 &')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"inqmnVzbJD1h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"18f8c5f6-ca5d-49e1-86c6-94ef99b480f6","executionInfo":{"status":"ok","timestamp":1534492176772,"user_tz":-480,"elapsed":2393,"user":{"displayName":"Camille Occeño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116044928297955637522"}}},"cell_type":"code","source":["! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":22,"outputs":[{"output_type":"stream","text":["https://d12db928.ngrok.io\r\n"],"name":"stdout"}]},{"metadata":{"id":"3Bh_PVLdQS4P","colab_type":"text"},"cell_type":"markdown","source":["Code for Downloading data from Google Drive\n","==="]},{"metadata":{"id":"IZK7c1IwPXme","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"outputId":"015246eb-1356-472a-88a1-caaeafd2d4d2","executionInfo":{"status":"ok","timestamp":1534492182169,"user_tz":-480,"elapsed":5347,"user":{"displayName":"Camille Occeño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116044928297955637522"}}},"cell_type":"code","source":["!pip install -U -q PyDrive\n","import os\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# 1. Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# choose a local (colab) directory to store the data.\n","local_download_path = os.path.expanduser('~/data')\n","try:\n","  os.makedirs(local_download_path)\n","except: pass\n","\n","# 2. Auto-iterate using the query syntax\n","#    https://developers.google.com/drive/v2/web/search-parameters\n","file_list = drive.ListFile(\n","    {'q': \"'1BbW7z2g7g-UJ1NlbSOMTw6g82SwRW8Df' in parents\"}).GetList()\n","\n","for f in file_list:\n","  # 3. Create & download by id.\n","  print('title: %s, id: %s' % (f['title'], f['id']))\n","  fname = os.path.join(local_download_path, f['title'])\n","  print('downloading to {}'.format(fname))\n","  f_ = drive.CreateFile({'id': f['id']})\n","  f_.GetContentFile(fname)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["title: reviews.txt, id: 1uwJihU8ETRWd6JfZIyegvFmX19bd-ZwT\n","downloading to /content/data/reviews.txt\n","title: labels.txt, id: 1TD9S27bVU7m5Azt5L7oOru5O2l2cwp0O\n","downloading to /content/data/labels.txt\n"],"name":"stdout"}]},{"metadata":{"id":"1OfpqBtTQZA0","colab_type":"text"},"cell_type":"markdown","source":["Preparing the Dataset\n","==="]},{"metadata":{"id":"G0f7tNdgIyyN","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ss6xttoF7hkB","colab_type":"code","colab":{}},"cell_type":"code","source":["with open('./data/reviews.txt', 'r') as file:\n","  features = file.read()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GoDv7SrAPjCa","colab_type":"code","colab":{}},"cell_type":"code","source":["features = features.split('\\n')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ej2p7FQeQepm","colab_type":"text"},"cell_type":"markdown","source":["## Getting trigrams"]},{"metadata":{"id":"qBVEXKrW7u9d","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer"],"execution_count":0,"outputs":[]},{"metadata":{"id":"n8GuWk817zDQ","colab_type":"code","colab":{}},"cell_type":"code","source":["def vectorizer(text):\n","  vec = CountVectorizer(binary=True, min_df=3, ngram_range=(3, 3), token_pattern='(?u)\\\\b[a-z0-9\\-\\_]{3,}\\\\b', stop_words='english')\n","  vec.fit(text)\n","  return vec"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-OYHI7L5VgKk","colab_type":"code","colab":{}},"cell_type":"code","source":["vec = vectorizer(features)\n","ngrams = vec.transform(features).toarray()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"k9j2BFFG79Wf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":134},"outputId":"8b860f27-f8c1-4dd1-b872-0b56faf29d5e","executionInfo":{"status":"ok","timestamp":1534492217907,"user_tz":-480,"elapsed":1066,"user":{"displayName":"Camille Occeño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116044928297955637522"}}},"cell_type":"code","source":["ngrams"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       ...,\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0]])"]},"metadata":{"tags":[]},"execution_count":30}]},{"metadata":{"id":"RFMNl8_XP08x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"2ade773b-4342-495c-d39e-658d23b0e440","executionInfo":{"status":"ok","timestamp":1534492219337,"user_tz":-480,"elapsed":1097,"user":{"displayName":"Camille Occeño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116044928297955637522"}}},"cell_type":"code","source":["ngrams.shape"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(25000, 15146)"]},"metadata":{"tags":[]},"execution_count":31}]},{"metadata":{"id":"mB-UuJMFQivM","colab_type":"text"},"cell_type":"markdown","source":["## One-hot encoding the labels"]},{"metadata":{"id":"unAcktV5P11x","colab_type":"code","colab":{}},"cell_type":"code","source":["with open('./data/labels.txt', 'r') as file:\n","  labels = file.read()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NaGtq7biP9uN","colab_type":"code","colab":{}},"cell_type":"code","source":["labels = np.array([1 if label == 'positive' else 0 for label in labels.split('\\n')])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6aQcyj2OQEbA","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.utils import to_categorical"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tIAzufoWQGko","colab_type":"code","colab":{}},"cell_type":"code","source":["labels = to_categorical(labels)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dkF2GcB1QnPI","colab_type":"text"},"cell_type":"markdown","source":["## Splitting the dataset"]},{"metadata":{"id":"OyZefu_VQJ4A","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, y_train, y_test = train_test_split(ngrams, labels[0:25000], test_size=0.30, stratify=labels[0:25000])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"T5LHtvCNRC8H","colab_type":"text"},"cell_type":"markdown","source":["Building the Model\n","==="]},{"metadata":{"id":"HBZjZW-Z8E4u","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D0CqLQEA8HWs","colab_type":"code","colab":{}},"cell_type":"code","source":["tf.reset_default_graph()\n","\n","with tf.name_scope('input'):\n","  input_features = tf.placeholder(dtype=tf.float32, shape=[None, ngrams.shape[1]],\n","                                 name='input_features')\n","  input_labels = tf.placeholder(dtype=tf.float32, shape=[None, labels.shape[1]],\n","                               name='input_labels')\n","\n","  with tf.name_scope('model'):\n","    weights = tf.Variable(tf.random_normal(shape=[ngrams.shape[1], labels.shape[1]]),\n","                          name='weights')\n","    biases = tf.Variable(tf.random_normal(shape=[labels.shape[1]]))\n","    linear_model = tf.add(tf.matmul(input_features, weights), biases)\n","    predictions = tf.nn.softmax(linear_model)\n","    \n","with tf.name_scope('training_ops'):\n","  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n","      logits=linear_model, labels=input_labels))\n","  train_op = tf.train.AdamOptimizer(learning_rate=1e-2).minimize(loss)\n","  tf.summary.scalar(name='loss', tensor=loss)\n","\n","with tf.name_scope('metrics'):\n","  correct_prediction = tf.cast(tf.equal(tf.argmax(predictions, 1),\n","                                         tf.argmax(input_labels, 1)), tf.float32)\n","  accuracy_op = tf.reduce_mean(correct_prediction)\n","  tf.summary.scalar(name='accuracy', tensor=accuracy_op)\n","\n","summary = tf.summary.merge_all()\n","writer = tf.summary.FileWriter(logdir='logs', graph=tf.get_default_graph())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gS1pF5ir-nL_","colab_type":"code","colab":{}},"cell_type":"code","source":["init_op = tf.global_variables_initializer()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"m6WWWGO9-3Sy","colab_type":"code","colab":{}},"cell_type":"code","source":["def next_batch(batch_size, features, labels):\n","  indices = np.arange(start=0, stop=features.shape[0])\n","  np.random.shuffle(indices)\n","  indices = indices[:batch_size]\n","  return features[indices], labels[indices]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Y8VSK1NN-rPx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1269},"outputId":"34f08d57-4d9f-44b5-a3db-a58ba7c7d83d","executionInfo":{"status":"error","timestamp":1534489295969,"user_tz":-480,"elapsed":77490,"user":{"displayName":"Camille Occeño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116044928297955637522"}}},"cell_type":"code","source":["with tf.Session() as sess:\n","  sess.run(init_op)\n","  \n","  # epochs = 10\n","  for epoch in range(10):\n","    for mini_batch in range(int(x_train.shape[0] / 16)):\n","      batch_x, batch_y = next_batch(batch_size=16, features=x_train, labels=y_train)\n","      \n","      _, train_loss, train_accuracy, train_summary = sess.run([train_op, loss,\n","                                                               accuracy_op,\n","                                                              summary],\n","                                              feed_dict={input_features: batch_x,\n","                                                        input_labels: batch_y})\n","      writer.add_summary(summary=train_summary, global_step=mini_batch)\n","    print('Epoch {}, loss : {}, accuracy : {}'.format(epoch, train_loss,\n","                                                      train_accuracy))  \n","  \n","  test_accuracy = sess.run(accuracy_op, feed_dict={input_features: x_test, input_labels: y_test})\n","  print('Test accuracy : {}'.format(test_accuracy))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Epoch 0, loss : 0.4602701961994171, accuracy : 0.75\n","Epoch 1, loss : 0.2450477033853531, accuracy : 0.875\n","Epoch 2, loss : 0.17651745676994324, accuracy : 1.0\n","Epoch 3, loss : 0.20565742254257202, accuracy : 0.9375\n","Epoch 4, loss : 0.2254587709903717, accuracy : 0.8125\n","Epoch 5, loss : 0.43419888615608215, accuracy : 0.8125\n","Epoch 6, loss : 0.3321280777454376, accuracy : 0.8125\n","Epoch 7, loss : 0.23762646317481995, accuracy : 0.9375\n","Epoch 8, loss : 0.2456846535205841, accuracy : 0.8125\n","Epoch 9, loss : 0.30711379647254944, accuracy : 0.875\n"],"name":"stdout"},{"output_type":"error","ename":"InternalError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInternalError\u001b[0m: Dst tensor is not initialized.\n\t [[Node: _arg_input/input_features_0_0/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_22__arg_input/input_features_0_0\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: metrics/Mean/_15 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_25_metrics/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-b3355546362f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                                                       train_accuracy))  \n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy : {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInternalError\u001b[0m: Dst tensor is not initialized.\n\t [[Node: _arg_input/input_features_0_0/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_22__arg_input/input_features_0_0\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: metrics/Mean/_15 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_25_metrics/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"]}]},{"metadata":{"id":"aQx28Ab_NdnU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":56},"outputId":"3a27929d-0f71-409e-d84e-af4f74e8b07c","executionInfo":{"status":"ok","timestamp":1534484150825,"user_tz":-480,"elapsed":1000,"user":{"displayName":"Abien Fred Agarap","photoUrl":"//lh6.googleusercontent.com/-ieGoakEpvaE/AAAAAAAAAAI/AAAAAAAAADk/RZG8D8fv-PM/s50-c-k-no/photo.jpg","userId":"109794435981185271543"}}},"cell_type":"code","source":["labels = ['Negative', 'Positive']\n","with tf.Session() as sess:\n","  sess.run(init_op)\n","  prediction_ = sess.run(predictions, feed_dict={input_features: x_test[1].reshape(-1, x_test.shape[1])})\n","  print(prediction_)\n","  print('predicted class : {}, true class : {}'.format(sess.run(tf.argmax(prediction_, 1)), labels[sess.run(tf.argmax(y_test[1]))]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[0.08523608 0.91476387]]\n","predicted class : [1], true class : Positive\n"],"name":"stdout"}]},{"metadata":{"id":"oDJfrmONUaMe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":56},"outputId":"8280248a-1977-4c62-94bd-23c0415b947f","executionInfo":{"status":"ok","timestamp":1534483717889,"user_tz":-480,"elapsed":1304,"user":{"displayName":"Abien Fred Agarap","photoUrl":"//lh6.googleusercontent.com/-ieGoakEpvaE/AAAAAAAAAAI/AAAAAAAAADk/RZG8D8fv-PM/s50-c-k-no/photo.jpg","userId":"109794435981185271543"}}},"cell_type":"code","source":["features[100]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'i find it so amazing that even after all these years  we are still talking about this movie  obviously this movie wasn  t that bad or else people wouldn  t even bother to talk about it . i personally enjoyed this film immensly  and still do  i guess this film isn  t for everyone  but it certainly did touch the hearts of many .  br    br   as for those that think that this film is  overrated  or  over  hyped  . . . well  we only have the movie  going public to thank for that  lol you see  it  s not critics  article writers that make a film  huge  or a  hit  with the general movie  going public . people make the film a huge success . with titanic  everyone was in awe . let  s face it  a film like this had never been made before . at least not with the type of special effects needed to really capture the essence of the ship actually sinking . this film is so accurate that even james cameron timed the actual sinking of the ship in the film with the real sinking that fateful day in april     . even the silverware for goodness sakes matched   br    br   give this movie a break you guys  the critics thought this movie would sink big time  when this movie actually came out and people started hearing by word of mouth  which is the best form of advertisement mind you  that this was a good  decent  movie worth seeing  then everyone started flocking to the theaters in droves to see this movie . . . not once  not twice  but maybe  times and more  so  i really wouldn  t say that this movie was  overhyped  . . . at least not like the buildup for the matrix reloaded or the hulk is being  overhyped  . ha  critics didn  t even think that titanic would make enough money to cover cameron  s gigantic film budget that it took to make this mammoth of a film . however  the films money took care of that    million budget and much more   br    br   personally  i love this film . however  this film might not be for everyone . don  t say that this film sucks just because of romance though  that is the most sexist thing i  ve ever heard  disliking a movie just because it has romance in it  the story was sweet . the dialogue could have been better  but let  s face it . . . the real star of the movie wasn  t leo or kate . . . it was that gigantic ship  i think all of the actors including dicaprio and winslet did a fine job . it  s not thier best work  i  ve seen much better work from both of them  but it wasn  t the worst i  ve seen on screen before . give them a break   br    br    '"]},"metadata":{"tags":[]},"execution_count":25}]},{"metadata":{"id":"0bQ7wJOfUg2B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"6708fe6b-6e0e-4116-97c8-3fa6bd765463","executionInfo":{"status":"ok","timestamp":1534483719317,"user_tz":-480,"elapsed":1233,"user":{"displayName":"Abien Fred Agarap","photoUrl":"//lh6.googleusercontent.com/-ieGoakEpvaE/AAAAAAAAAAI/AAAAAAAAADk/RZG8D8fv-PM/s50-c-k-no/photo.jpg","userId":"109794435981185271543"}}},"cell_type":"code","source":["labels[100]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 1.], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":26}]},{"metadata":{"id":"W-0XXsaKW5GQ","colab_type":"code","colab":{}},"cell_type":"code","source":["ngrams_example = vec.transform(['the food was extremely bad!']).toarray()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"buuh0t8DXW7t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":56},"outputId":"f738786a-432e-4b56-b16e-d9f787f9df20","executionInfo":{"status":"ok","timestamp":1534484234291,"user_tz":-480,"elapsed":1113,"user":{"displayName":"Abien Fred Agarap","photoUrl":"//lh6.googleusercontent.com/-ieGoakEpvaE/AAAAAAAAAAI/AAAAAAAAADk/RZG8D8fv-PM/s50-c-k-no/photo.jpg","userId":"109794435981185271543"}}},"cell_type":"code","source":["labels = ['Negative', 'Positive']\n","with tf.Session() as sess:\n","  sess.run(init_op)\n","  prediction_ = sess.run(predictions, feed_dict={input_features: ngrams_example.reshape(-1, ngrams_example.shape[1])})\n","  print(prediction_)\n","  print('predicted class : {}'.format(sess.run(tf.argmax(prediction_, 1))))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[0.67699635 0.32300368]]\n","predicted class : [0]\n"],"name":"stdout"}]}]}